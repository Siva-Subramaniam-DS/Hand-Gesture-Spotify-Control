{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Zc3mnvC36js"
   },
   "source": [
    "# Hand Gesture Recognition & Mapping to Bit Structure\n",
    "### 📌 Problem Statement  \n",
    "Hand gesture recognition is an intuitive way to interact with devices. The goal of this challenge is to create a system that can recognize six hand gestures and map them to specific actions.  \n",
    "\n",
    "## 🎯 Objectives:\n",
    "- Train a model to recognize six hand gestures:  \n",
    "  - **Thumbs Up** → Volume Up  \n",
    "  - **Thumbs Down** → Volume Down  \n",
    "  - **Point Left** → Previous Track  \n",
    "  - **Point Right** → Next Track  \n",
    "  - **Open Palm** → Activation Signal  \n",
    "  - **Fist** → Play/Pause  \n",
    "- Implement a **bit mapping function** for gesture-based control.  \n",
    "- Optimize for **real-time** performance.  \n",
    "- Ensure the system **only recognizes gestures after detecting an Open Palm**.  \n",
    "- **Collect and preprocess your own dataset** for training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQpQ5G-d4BYO"
   },
   "source": [
    "🔹 Step 1: Install Required Libraries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MT3UoKOE3k26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.10.21)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (76.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.69.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (24.2.0)\n",
      "Requirement already satisfied: jax in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (0.5.2)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (3.7.1)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: scipy>=1.11.1 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax->mediapipe) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (1.4.8)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: rich in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sivap\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python tensorflow mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxIvVAeg4En1"
   },
   "source": [
    "🔹 Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UtWyVqvI4RLR"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4WY3a_P4RhS"
   },
   "source": [
    "🔹 Step 3: Create Your Own Dataset\n",
    "\n",
    "📝 Task: You need to collect images of different hand gestures. This dataset will be used to train your model.\n",
    "\n",
    "Instructions:\n",
    "Capture images for each of the six gestures.\n",
    "Save them in labeled folders (Thumbs_Up/, Thumbs_Down/, etc.).\n",
    "Collect at least 100 images per gesture for better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = 'Train'  \n",
    "data_test = 'Test' \n",
    "# Replace with the correct path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands.Hands()\n",
    "\n",
    "# data loading and preprocessing\n",
    "# Define image size\n",
    "img_size = (64, 64)  # You can adjust the size as needed\n",
    "\n",
    "# Create empty lists to store images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Loop through subdirectories (gestures)\n",
    "for gesture in os.listdir(data_train):\n",
    "    gesture_path = os.path.join(data_train, gesture)\n",
    "    if os.path.isdir(gesture_path):\n",
    "        # Loop through images in each gesture folder\n",
    "        for image_file in os.listdir(gesture_path):\n",
    "            image_path = os.path.join(gesture_path, image_file)\n",
    "            # Read and resize the image\n",
    "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load in grayscale\n",
    "            img = cv2.resize(img, img_size)\n",
    "            # Append image and label to lists\n",
    "            images.append(img)\n",
    "            labels.append(gesture)  # Use gesture folder name as label\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Normalize pixel values to range [0, 1]\n",
    "images = images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBQdVfN34bMC"
   },
   "source": [
    "🔹 Step 4: Implement Gesture Recognition\n",
    "\n",
    "📝 Task: Use any model to classify gestures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sASi8fNb4b6P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sivap\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.2898 - loss: 1.7057\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.2652 - loss: 2.2772 \n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6080 - loss: 1.6197 \n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3617 - loss: 1.6801 \n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.3826 - loss: 1.5189 \n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6487 - loss: 1.3889\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5000 - loss: 1.3287 \n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7860 - loss: 1.1795 \n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7803 - loss: 1.0511 \n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8930 - loss: 0.8877 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Build a simple CNN model using TensorFlow/Keras\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)), \n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(np.unique(labels)), activation='softmax')  # Output layer with number of classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# One-hot encode labels (or use sparse_categorical_crossentropy)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Reshape images for CNN input\n",
    "images = images.reshape(-1, 64, 64, 1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(images, labels_encoded, epochs=10)\n",
    "\n",
    "\n",
    "# Save the model\n",
    "model.save('hand_gesture_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXNikDd44nEa"
   },
   "source": [
    "🔹 Step 5: Map Gestures to Bit Structure\n",
    "\n",
    "📝 Task: Convert each gesture into a bit pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PCyUbhZp4pCv"
   },
   "outputs": [],
   "source": [
    "gesture_mapping = {\n",
    "    \"Thumbs Up\": 0b000001,  # Volume Up\n",
    "    \"Thumbs Down\": 0b000010,  # Volume Down\n",
    "    \"Point Left\": 0b000100,  # Previous Track\n",
    "    \"Point Right\": 0b001000,  # Next Track\n",
    "    \"Open Palm\": 0b010000,  # Activation Signal\n",
    "    \"Fist\": 0b100000,  # Play/Pause\n",
    "}  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOSTVa1e4teu"
   },
   "source": [
    "🔹 Step 6: Implement Open Palm Activation\n",
    "\n",
    "📝 Task: Ensure gestures are only detected after an open palm is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ynvbCS5C4zDO"
   },
   "outputs": [],
   "source": [
    "activation_flag = False  # Initialize activation flag\n",
    "# After gesture recognition:\n",
    "detected_gesture = ...  # Get the detected gesture from your model\n",
    "action_code = gesture_mapping.get(detected_gesture, None)\n",
    "\n",
    "if detected_gesture == \"Open Palm\":\n",
    "        activation_flag = True\n",
    "        print(\"Open Palm detected! Activation enabled.\")\n",
    "\n",
    "if activation_flag:\n",
    "        # Perform gesture recognition and mapping for other gestures\n",
    "        if detected_gesture in gesture_mapping:\n",
    "            action_code = gesture_mapping[detected_gesture]\n",
    "            print(f\"Detected gesture: {detected_gesture}, Action code: {action_code}\")\n",
    "            # Use action_code to control actions (e.g., volume, track, play# After gesture recognition:\n",
    "        elif action_code == gesture_mapping[\"Thumbs Up\"]:\n",
    "            # Code to increase volume\n",
    "            print(\"Increasing volume...\")\n",
    "        elif action_code == gesture_mapping[\"Thumbs Down\"]:\n",
    "            # Code to decrease volume\n",
    "            print(\"Decreasing volume...\")\n",
    "        elif action_code == gesture_mapping[\"Point Left\"]:\n",
    "            # Code for previous track\n",
    "            print(\"Previous track...\")\n",
    "        elif action_code == gesture_mapping[\"Point Right\"]:\n",
    "            # Code for next track\n",
    "            print(\"Next track...\")\n",
    "        elif action_code == gesture_mapping[\"Open Palm\"]:\n",
    "            # Code for activation signal\n",
    "            print(\"Activation signal...\")\n",
    "        elif action_code == gesture_mapping[\"Fist\"]:\n",
    "            # Code for play/pause\n",
    "            print(\"Play/Pause...\")\n",
    "        else:\n",
    "            print(f\"Unknown gesture: {detected_gesture}\") \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYH6_1Ie4zqe"
   },
   "source": [
    "🔹 Step 7: Test Your Model\n",
    "\n",
    "📝 Task: Run real-time detection to validate your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fb_DgxHJ44hQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Point Right, Action code: 8\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Thumbs Up, Action code: 1\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Thumbs Down, Action code: 2\n",
      "Detected gesture: Point Left, Action code: 4\n",
      "Detected gesture: Fist, Action code: 32\n",
      "Open Palm detected! Activation enabled.\n",
      "Detected gesture: Open Palm, Action code: 16\n"
     ]
    }
   ],
   "source": [
    "# Initialize MediaPipe Hands and Drawing modules\n",
    "mp_hands = mp.solutions.hands.Hands()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Start capturing video from the default camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip the frame horizontally\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with MediaPipe Hands\n",
    "    results = mp_hands.process(frame_rgb)\n",
    "\n",
    "    # Check if hands are detected\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Draw hand landmarks on the frame\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp.solutions.hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Get hand landmarks as a NumPy array\n",
    "            landmarks = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark])\n",
    "\n",
    "            # Preprocess landmarks (e.g., normalize, extract features)\n",
    "            # ... (Your preprocessing code here)\n",
    "\n",
    "            # Make predictions using your trained model\n",
    "            # prediction = model.predict(preprocessed_landmarks)\n",
    "            # detected_gesture = ...  # Get the predicted gesture label\n",
    "\n",
    "            # Replace this with your actual model prediction and gesture label extraction\n",
    "            # For demonstration purposes, let's assume a random gesture\n",
    "            import random\n",
    "            gestures = list(gesture_mapping.keys())\n",
    "            detected_gesture = random.choice(gestures)\n",
    "            \n",
    "\n",
    "            # Implement Open Palm Activation\n",
    "            if detected_gesture == \"Open Palm\":\n",
    "                activation_flag = True\n",
    "                print(\"Open Palm detected! Activation enabled.\")\n",
    "\n",
    "            if activation_flag:\n",
    "                # Perform gesture recognition and mapping for other gestures\n",
    "                if detected_gesture in gesture_mapping:\n",
    "                    action_code = gesture_mapping[detected_gesture]\n",
    "                    print(f\"Detected gesture: {detected_gesture}, Action code: {action_code}\")\n",
    "                    # Use action_code to control actions (e.g., volume, track, play/pause)\n",
    "                    # ... (Your action triggering code here)\n",
    "                else:\n",
    "                    print(f\"Unknown gesture: {detected_gesture}\")\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Hand Gesture Recognition', frame)\n",
    "\n",
    "    # Exit the loop if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOHgezH9Erg7kA/Qgh8dnLk",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
